import dataclasses
from typing import List, Optional, Union, Any
from vllm import LLM

@dataclasses.dataclass
class MedicalCase:
    case_id: str
    image_path: str
    report_text: str


@dataclasses.dataclass
class VLMInput:
    content: List[Union[str, dict]]


class VLMRefiner:
    def __init__(self, vlm: Any, k_neighbors: int = 5):
        self.vlm = vlm
        self.k_neighbors = k_neighbors

        self.persona = "You are an expert radiology assistant for CT interpretation and report generation."
        self.task = (
            "Refine the provided `base report` into a `final report` using few-shot exemplars "
            "to match expert style, structure, and clinical detail."
        )
        self.context_desc = (
            "1. Input: [input CT scan, `base report`]\n"
            "2. Exemplars: Top-k visually similar CT scans with reports, retrieved from Stage 1."
        )
        self.procedure = (
            "1. Analyze the input CT scan and its `base report`.\n"
            "2. Review exemplar CT-report pairs to learn reporting style and diagnostic detail.\n"
            "3. Synthesize the `final report` in a consistent radiology style.\n"
            "4. Adapt exemplar guidance without copying or redundancy.\n"
            "5. Output only the refined report."
        )
        self.instructions = (
            "1. Do not include any explanations or meta-comments.\n"
            "2. Ensure the `final report` is clinically precise and aligns with clinical conventions."
        )

    def retrieve_nearest_neighbors(self, input_embedding: Any) -> List[MedicalCase]:
        return [
            MedicalCase(
                case_id=f"neighbor_{i}",
                image_path=f"path/to/neighbor_{i}.png",
                report_text=getReport(case_id),
            )
            for i in range(1, self.k_neighbors + 1)
        ]

    def construct_prompt(
        self, target_case: MedicalCase, neighbors: List[MedicalCase]
    ) -> List[Union[str, dict]]:
        prompt_sequence = []

        system_text = (
            f"Persona: {self.persona}\n"
            f"Task: {self.task}\n"
            f"Context Provided:\n{self.context_desc}\n"
            f"Procedure:\n{self.procedure}\n"
            f"Instructions:\n{self.instructions}\n\n"
            "Here are the Exemplars (Context Item 2):"
        )
        prompt_sequence.append({"type": "text", "text": system_text})

        for idx, neighbor in enumerate(neighbors):
            prompt_sequence.append(
                {
                    "type": "image_url",
                    "image_url": {"url": neighbor.image_path},
                    "label": f"Example Case {idx+1}",
                }
            )
            prompt_sequence.append(
                {
                    "type": "text",
                    "text": f"Expert Report for Example {idx+1}:\n{neighbor.report_text}\n\n",
                }
            )

        prompt_sequence.append(
            {
                "type": "text",
                "text": "Now, here is the Input (Context Item 1) to refine:",
            }
        )

        prompt_sequence.append(
            {
                "type": "image_url",
                "image_url": {"url": target_case.image_path},
                "label": "Target Input Scan",
            }
        )

        prompt_sequence.append(
            {
                "type": "text",
                "text": f"Base Report (Generated by Stage 1):\n{target_case.report_text}\n\n",
            }
        )

        prompt_sequence.append(
            {"type": "text", "text": "Generate the final refined report:"}
        )

        return prompt_sequence

    def refine_report(self, input_image_path: str, base_report_text: str) -> str:
        target_case = MedicalCase(
            case_id="target_001",
            image_path=input_image_path,
            report_text=base_report_text,
        )

        neighbors = self.retrieve_nearest_neighbors(input_embedding=None)

        prompt_payload = self.construct_prompt(target_case, neighbors)

        print("Sending prompt to VLM...")
        final_report = self.vlm.generate(prompt_payload)

        return final_report


if __name__ == "__main__":
    vlm_llava_med = LLM(model="microsoft/llava-med-v1.5-mistral-7b", limit_mm_per_prompt={"image": 5})

    refiner = VLMRefiner(vlm=vlm_llava_med, k_neighbors=5)

    input_scan = "path/to/patient_scan.jpg"
    base_report = "<base report>"

    final_report = refiner.refine_report(input_scan, base_report)

    print("-" * 30)
    print(final_report)
    print("-" * 30)


